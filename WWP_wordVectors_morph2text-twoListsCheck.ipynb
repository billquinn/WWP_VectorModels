{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WWP Sort and Write Parser\n",
    "\n",
    "This parser uses the encoding practices of the WWP to sort texts into various categories. These different datasets help create different models for word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import fnmatch\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def morph2text(file_name):\n",
    "'''\n",
    "Input: an .xml file\n",
    "Output: a string to be written to a .txt file\n",
    "'''\n",
    "    with open(file_name, 'rt') as read_file:\n",
    "        \n",
    "        parser = etree.XMLParser(ns_clean=True, recover = True)\n",
    "        morphTree = ET.parse(read_file, parser=parser)\n",
    "        content_list = []\n",
    "\n",
    "        for node in morphTree.findall('.//reg'):\n",
    "            lines = ''.join(ET.tostring(node,\n",
    "                                        encoding='unicode',\n",
    "                                        method='text')).replace('\\n',' ').replace('\\t',' ').strip()\n",
    "            clean_lines = re.sub(' +',' ', lines)\n",
    "            content_list.append(clean_lines)\n",
    "\n",
    "        return ' '.join(str(v) for v in content_list).replace('\\t','').replace('\\n','').lower()\n",
    "\n",
    "def get_pubPlace(tree):\n",
    "'''\n",
    "Input: the tree structure of an .xml file\n",
    "Output: a string of text from the specified tag\n",
    "'''\n",
    "    pubPlace = tree.find('.//wwp:sourceDesc//wwp:imprint/wwp:pubPlace', namespaces=ns).text.lower()\n",
    "    return (pubPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/fullTexts-XSLT/*.xml\")\n",
    "\n",
    "seven_files = glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/17c/morphadorned/*.xml\")\n",
    "eight_files = glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/18c/morphadorned/*.xml\")\n",
    "nine_files = glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/19c/morphadorned/*.xml\")\n",
    "\n",
    "seventeenth_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph-eme_17c.txt'\n",
    "eighteenth_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph-eme_18c.txt'\n",
    "nineteenth_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph_19c.txt'\n",
    "all_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph_allTexts.txt'\n",
    "\n",
    "us_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph_us.txt'\n",
    "global_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph_non-us.txt'\n",
    "\n",
    "eme_p_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph-eme_gi-p.txt'\n",
    "eme_lg_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph-eme_gi-lg.txt'\n",
    "\n",
    "gi_p_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph_gi-p.txt'\n",
    "gi_lg_path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/wwo_reg-morph_gi-lg.txt'\n",
    "\n",
    "\n",
    "ns = {'wwp':'http://www.wwp.northeastern.edu/ns/textbase'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:06:38.971105\n"
     ]
    }
   ],
   "source": [
    "# Write by Century\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "with open(seventeenth_path, \"a\") as seventhC, open(eighteenth_path, \"a\") as eighthC, open(nineteenth_path, \"a\") as ninethC, open(all_path, \"a\") as allTexts:\n",
    "    \n",
    "    for file_name in seven_files:\n",
    "        seven_content = morph2text(file_name)\n",
    "        seventhC.write(seven_content + '\\n')\n",
    "        allTexts.write(seven_content + '\\n')\n",
    "        \n",
    "    for file_name in eight_files:\n",
    "        eight_content = morph2text(file_name)\n",
    "        eighthC.write(eight_content + '\\n')\n",
    "        allTexts.write(eight_content + '\\n')\n",
    "    \n",
    "    for file_name in nine_files:\n",
    "        nine_content = morph2text(file_name)\n",
    "        ninethC.write(nine_content + '\\n')\n",
    "        allTexts.write(nine_content + '\\n')\n",
    "        \n",
    "        \n",
    "print (datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usPubPlaces = ['newport, ri', 'newburyport, ma', 'philadelphia and new york', \n",
    "            'washington, dc', 'boston', 'new york', 'philadelphia', 'baltimore', \n",
    "            'salem, massachusetts', 'dedham, ma', 'cambridge, massachusetts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:00.048962\n"
     ]
    }
   ],
   "source": [
    "# Write by Place\n",
    "startTime = datetime.now()\n",
    "                \n",
    "with open(us_path, \"a\") as usTexts, open(global_path, \"a\") as globalTexts:\n",
    "    \n",
    "    for file_name in list_of_files:\n",
    "        file = open(file_name, 'rt')\n",
    "        tree = ET.parse(file)\n",
    "        place = get_pubPlace(tree)\n",
    "        file.close()\n",
    "        file_regex = re.search(r'full-(.*).xml', str(file_name)).group(1)\n",
    "    \n",
    "        \n",
    "        for name in glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/1?c/morphadorned/*.xml\"):\n",
    "            if str(file_regex) in name:\n",
    "                content_text = morph2text(name)\n",
    "        \n",
    "                if place in usPubPlaces:\n",
    "                    usTexts.write(content_text + '\\n')\n",
    "                else:\n",
    "                    globalTexts.write(content_text + '\\n')\n",
    "\n",
    "print (datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:08.621423\n"
     ]
    }
   ],
   "source": [
    "# Write by Element\n",
    "startTime = datetime.now()\n",
    "                \n",
    "with open(gi_p_path, \"a\") as gi_p, open(gi_lg_path, \"a\") as gi_lg:\n",
    "    for file in glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/gi-lg/reg-morph/*.xml\"):\n",
    "        content_text = morph2text(file)\n",
    "        gi_p.write(content_text)\n",
    "        \n",
    "    for file in glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/gi-p/reg-morph/*.xml\"):\n",
    "        content_text = morph2text(file)\n",
    "        gi_lg.write(content_text)\n",
    "        \n",
    "with open(eme_p_path, \"a\") as eme_p, open(eme_lg_path, \"a\") as eme_lg:\n",
    "    for file in glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/gi-lg/morph-eme/*.xml\"):\n",
    "        content_text = morph2text(file)\n",
    "        eme_p.write(content_text)\n",
    "        \n",
    "    for file in glob.glob(\"/Users/williamquinn/Desktop/DH/Python/WWP/Morphadorned/gi-p/morph-eme/*.xml\"):\n",
    "        content_text = morph2text(file)\n",
    "        eme_lg.write(content_text)\n",
    "\n",
    "\n",
    "print (datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write by .xml (post-morphadorned)\n",
    "startTime = datetime.now()\n",
    "                \n",
    "path = '/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/post-morphadorned/'\n",
    "for file in glob.glob('/Users/williamquinn/Desktop/DH/Python/WWP/WWP Word Vectors/Output/*-morph/*.xml'):\n",
    "#     file_regex = re.search(r'full-(.*).xml', str(file_name)).group(1)\n",
    "    with open(path + file_regex + \".txt\", \"w\") as file2write:\n",
    "        content_text = morph2text(file2write)\n",
    "        file2write.close()\n",
    "    \n",
    "\n",
    "print (datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words \n",
      "All texts count: 12440955\n",
      "\n",
      "US texts count: 2468812 \n",
      "Global texts count: 10386905\n",
      "17C texts count: 4496620 \n",
      "18c texts count: 3963521 \n",
      "19c texts count: 3980814\n",
      "\n",
      "gi-p 5574904 \n",
      "gi-lg 9476694 \n",
      "eme-p 5572887 \n",
      "eme-lg 9472856\n",
      "\n",
      " 0:00:16.856126\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "sev_count = 0\n",
    "eig_count = 0\n",
    "nin_count = 0\n",
    "all_count = 0\n",
    "us_count = 0\n",
    "global_count = 0\n",
    "gi_p_count = 0\n",
    "gi_lg_count = 0\n",
    "eme_p_count = 0\n",
    "eme_lg_count = 0\n",
    "\n",
    "with open(us_path, \"r\") as usTexts, open(global_path, \"r\") as globalTexts:\n",
    "    for w in usTexts.read().split():\n",
    "        us_count = us_count + 1\n",
    "    for w in globalTexts.read().split():\n",
    "        global_count = global_count + 1\n",
    "\n",
    "with open(seventeenth_path, \"r\") as sev, open(eighteenth_path, \"r\") as eig, open(nineteenth_path, \"r\") as nin, open(all_path, \"r\") as allt:\n",
    "    for w in sev.read().split():\n",
    "        sev_count = sev_count + 1\n",
    "    for w in eig.read().split():\n",
    "        eig_count = eig_count + 1\n",
    "    for w in nin.read().split():\n",
    "        nin_count = nin_count + 1\n",
    "    for w in allt.read().split():\n",
    "        all_count = all_count + 1\n",
    "        \n",
    "with open(gi_p_path, \"r\") as gi_p, open(gi_lg_path, \"r\") as gi_lg, open(eme_p_path, \"r\") as eme_p, open(eme_lg_path, \"r\") as eme_lg:\n",
    "    for w in gi_p.read().split():\n",
    "        gi_p_count = gi_p_count + 1\n",
    "    for w in gi_lg.read().split():\n",
    "        gi_lg_count = gi_lg_count + 1\n",
    "        \n",
    "    for w in eme_p.read().split():\n",
    "        eme_p_count = eme_p_count + 1\n",
    "    for w in eme_lg.read().split():\n",
    "        eme_lg_count = eme_lg_count + 1\n",
    "\n",
    "\n",
    "\n",
    "print (\"Number of Words\", \"\\nAll texts count:\", all_count) \n",
    "print (\"\\nUS texts count:\", us_count, \"\\nGlobal texts count:\", global_count)\n",
    "print (\"17C texts count:\", sev_count, \"\\n18c texts count:\", eig_count, \"\\n19c texts count:\", nin_count)\n",
    "print (\"\\ngi-p\", gi_p_count, \"\\ngi-lg\", gi_lg_count, \"\\neme-p\", eme_p_count, \"\\neme-lg\", eme_lg_count)\n",
    "print ('\\n', datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
